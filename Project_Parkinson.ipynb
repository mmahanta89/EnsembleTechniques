{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import pandas_profiling\n",
    "\n",
    "#to get all columns in dataframe on page\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "import PyPDF2\n",
    "\n",
    "from scipy.stats import kurtosis\n",
    "from scipy.stats import skew\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#listing and evaluating each file\n",
    "for f in os.listdir():\n",
    "    print(f.ljust(30) +\"--\" + str(round(os.path.getsize(f) / 1000000, 2)) + 'MB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'Data - parkinsons.names'\n",
    "file = open(filename,mode='r')\n",
    "text = file.read()\n",
    "file.close()\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- This document contains the details on data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "filename = 'LETTER G - Z.pdf'\n",
    "# creating an object \n",
    "file = open(filename, 'rb')\n",
    "\n",
    "# creating a pdf reader object\n",
    "fileReader = PyPDF2.PdfFileReader(file)\n",
    "\n",
    "# print the number of pages in pdf file\n",
    "print(fileReader.numPages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pageObj = fileReader.getPage(0)\n",
    "pageObj.extractText()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(fileReader.numPages):\n",
    "    pageObj = fileReader.getPage(i)\n",
    "    print(pageObj.extractText())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import IFrame\n",
    "IFrame(filename, width=600, height=900)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- This pdf contains the letter details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_p=pd.read_csv('Data - Parkinsons')\n",
    "print(\"Shape:\",data_p.shape)\n",
    "print(\"Contains 195 rows and 24 columns\")\n",
    "data_p.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_p.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=data_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Total 24 columns are present\n",
    "- Majority of columns are numeric and Float\n",
    "- status column is int and contins 0 & 1 represnting healthy and parkinson's"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Attribute Information:\n",
    "\n",
    "- Matrix column entries (attributes):\n",
    "- name - ASCII subject name and recording number\n",
    "- MDVP:Fo(Hz) - Average vocal fundamental frequency\n",
    "- MDVP:Fhi(Hz) - Maximum vocal fundamental frequency\n",
    "- MDVP:Flo(Hz) - Minimum vocal fundamental frequency\n",
    "- MDVP:Jitter(%),MDVP:Jitter(Abs),MDVP:RAP,MDVP:PPQ,Jitter:DDP - Several measures of variation in fundamental frequency\n",
    "- MDVP:Shimmer,MDVP:Shimmer(dB),Shimmer:APQ3,Shimmer:APQ5,MDVP:APQ,Shimmer:DDA - Several measures of variation in amplitude\n",
    "- NHR,HNR - Two measures of ratio of noise to tonal components in the voice\n",
    "- RPDE,D2 - Two nonlinear dynamical complexity measures\n",
    "- DFA - Signal fractal scaling exponent\n",
    "- spread1,spread2,PPE - Three nonlinear measures of fundamental frequency variation \n",
    "\n",
    "#### Target Column\n",
    "- status - Health status of the subject (one) - Parkinson's, (zero) - healthy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.describe(include='all')\n",
    "df.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The rows of the CSV file contain an instance corresponding to one voice recording. \n",
    "- There are around six recordings per patient, the name of the patient is identified in the first column\n",
    "- Column values in tables are varying in scale and ranging from negative to positive\n",
    "- All column values shows real numbers and no abnormal details appeared so far\n",
    "- Name column is of not much importance for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.status.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.status.value_counts(1)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 75% of data is related for patient having Parkinson's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rearranging - moving status column towards end of file\n",
    "stat=df.pop('status') \n",
    "df['status'] = stat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Univariate Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Analyzing Frequencies\n",
    "- MDVP:Fo(Hz) - Average vocal fundamental frequency\n",
    "- MDVP:Fhi(Hz) - Maximum vocal fundamental frequency\n",
    "- MDVP:Flo(Hz) - Minimum vocal fundamental frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axes = plt.subplots(1, 3, figsize=(15,8), sharey='row')\n",
    "\n",
    "sns.distplot(df['MDVP:Flo(Hz)'],ax=axes[0],axlabel=\"MDVP:Flo(Hz)-Min-\" + \"skew:\" + str(skew(df['MDVP:Flo(Hz)'])))\n",
    "sns.distplot(df['MDVP:Fo(Hz)'],ax=axes[1],axlabel=\"MDVP:Fo(Hz)-Avg-\" + \"skew:\" +str(skew(df['MDVP:Fo(Hz)'])))\n",
    "sns.distplot(df['MDVP:Fhi(Hz)'],ax=axes[2],axlabel=\"MDVP:Fhi(Hz)-Max-\" + \"skew:\" +str(skew(df['MDVP:Fhi(Hz)'])))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Maximum vocal fundamental frequency is positively skewed, majority of the values are around 100-200 but few outliers beyond 300 is dragging its tail and making it poitively skewed. High outliers presence\n",
    "- Average vocal fundamental frequency is almost symmetrical with skewness around 0.6. Highest peak concentrtion of data is around 100-150\n",
    "- Minimum vocal fundamental frequency is comparativley more positivley skewed then average and less skewed than max. Majority of values are between 75-150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Analyzing\n",
    "- MDVP:Jitter(%),MDVP:Jitter(Abs),MDVP:RAP,MDVP:PPQ,Jitter:DDP - Several measures of variation in fundamental frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axes = plt.subplots(2,3,figsize=(15,8)) \n",
    "sns.distplot(df['MDVP:Jitter(%)'],ax=axes[0,0],axlabel=\"MDVP:Jitter(%)-\" + \"skew:\" + str(skew(df['MDVP:Jitter(%)'])) )\n",
    "sns.distplot(df['MDVP:Jitter(Abs)'],ax=axes[0,1],axlabel=\"MDVP:Shimmer(dB)-\" + \"skew:\" + str(skew(df['MDVP:Jitter(Abs)'])) )\n",
    "sns.distplot(df['MDVP:RAP'],ax=axes[0,2],axlabel=\"Shimmer:APQ3-\" + \"skew:\" + str(skew(df['MDVP:RAP'])) )\n",
    "sns.distplot(df['MDVP:PPQ'],ax=axes[1,0],axlabel=\"Shimmer:APQ5-\" + \"skew:\" + str(skew(df['MDVP:PPQ'])) )\n",
    "sns.distplot(df['Jitter:DDP'],ax=axes[1,1],axlabel=\"MDVP:APQ-\" + \"skew:\" + str(skew(df['Jitter:DDP']))) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Positive skewness present in all columns in grpahs present\n",
    "- No major peaks present in longer tails representing the values are very less\n",
    "- HIgh outliers presence in all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Analyzing \n",
    "- MDVP:Shimmer,MDVP:Shimmer(dB),Shimmer:APQ3,Shimmer:APQ5,MDVP:APQ,Shimmer:DDA - Several measures of variation in amplitude\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axes = plt.subplots(2,3,figsize=(15,8)) \n",
    "sns.distplot(df['MDVP:Shimmer'],ax=axes[0,0],axlabel=\"MDVP:Shimmer-\" + \"skew:\" + str(skew(df['MDVP:Shimmer'])) )\n",
    "sns.distplot(df['MDVP:Shimmer(dB)'],ax=axes[0,1],axlabel=\"MDVP:Shimmer(dB)-\" + \"skew:\" + str(skew(df['MDVP:Shimmer(dB)'])) )\n",
    "sns.distplot(df['Shimmer:APQ3'],ax=axes[0,2],axlabel=\"Shimmer:APQ3-\" + \"skew:\" + str(skew(df['Shimmer:APQ3'])) )\n",
    "sns.distplot(df['Shimmer:APQ5'],ax=axes[1,0],axlabel=\"Shimmer:APQ5-\" + \"skew:\" + str(skew(df['Shimmer:APQ5'])) )\n",
    "sns.distplot(df['MDVP:APQ'],ax=axes[1,1],axlabel=\"MDVP:APQ-\" + \"skew:\" + str(skew(df['MDVP:APQ']))) \n",
    "sns.distplot(df['Shimmer:DDA'],ax=axes[1,2],axlabel=\"Shimmer:DDA-\" + \"skew:\" + str(skew(df['Shimmer:DDA'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Positive skewness present in all columns in grpahs present\n",
    "- No major peaks present in longer tails representing the values are very less\n",
    "- majority of peak number of values are close to zero\n",
    "- High outliers presence in all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Analyzing NHR & HNR - Noises\n",
    "- NHR,HNR - Two measures of ratio of noise to tonal components in the voice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axes = plt.subplots(1, 2, figsize=(15,8), sharey='row')\n",
    "\n",
    "sns.distplot(df['NHR'],ax=axes[0],axlabel=\"NHR-\" + \"skew:\" + str(skew(df['NHR'])))\n",
    "sns.distplot(df['HNR'],ax=axes[1],axlabel=\"HNR-\" + \"skew:\" +str(skew(df['HNR'])))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#same y-scale is not providing proper results\n",
    "f, axes = plt.subplots(1, 2, figsize=(15,8))\n",
    "\n",
    "sns.distplot(df['NHR'],ax=axes[0],axlabel=\"NHR-\" + \"skew:\" + str(skew(df['NHR'])))\n",
    "sns.distplot(df['HNR'],ax=axes[1],axlabel=\"HNR-\" + \"skew:\" +str(skew(df['HNR'])))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- for NHR, high positive skewness\n",
    "- but the peaks are very low representing not a lot of values are present on those range of values\n",
    "- majority of values are rangig between 0.00-0.05\n",
    "- More outlier presence for NHR compared to HNR\n",
    "- HNR has slight negetive skewness but overll looks normally ditributed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Analyzing RPDE,D2 \n",
    "- Two nonlinear dynamical complexity measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axes = plt.subplots(1, 2, figsize=(15,8))\n",
    "\n",
    "sns.distplot(df['RPDE'],ax=axes[0],axlabel=\"RPDE-\" + \"skew:\" + str(skew(df['RPDE'])))\n",
    "sns.distplot(df['D2'],ax=axes[1],axlabel=\"D2-\" + \"skew:\" +str(skew(df['D2'])))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Both columns are less skewed and have close to normal distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Analyzing DFA - Signal fractal scaling exponent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(df['DFA'],axlabel=\"DFA-\" + \"skew:\" + str(skew(df['DFA'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Distribution is very less skewed and have close to normal distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Analyzing spread1,spread2,PPE \n",
    "- Three nonlinear measures of fundamental frequency variation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axes = plt.subplots(1, 3, figsize=(15,8))\n",
    "\n",
    "sns.distplot(df['spread1'],ax=axes[0],axlabel=\"spread1-\" + \"skew:\" + str(skew(df['spread1'])))\n",
    "sns.distplot(df['spread2'],ax=axes[1],axlabel=\"spread2-\" + \"skew:\" +str(skew(df['spread2'])))\n",
    "sns.distplot(df['PPE'],ax=axes[2],axlabel=\"PPE-\" + \"skew:\" +str(skew(df['PPE'])))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- skewness between0-1 for all. Almost normally distributed\n",
    "- slight outlier presence in PPE and spread1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bivariate Ananlysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,10))\n",
    "sns.heatmap(df.corr(), annot=True, fmt='.2f')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- from correlation details we can observe almost all the attributes are ranging between 0.2-0.5 in positive side and 2 negative correlation at -0.38\n",
    "- MDVP:Fo & Flo are having same impact on Status of -0.38\n",
    "- similarly all attributes related to Jitter are showing similar impact on status\n",
    "- Similarly all atrributes related to Shimmer are showing similar behaviour with status\n",
    "- There is a high correlation between attributes related to Jitter and Shimmer, you can observe the light & dark orange square formations for these columns in heatmap\n",
    "- HNR has high -ve correlation with all attributes related to Jitter and Shimmer\n",
    "- Highest positive/negative correlation noticed is with spread1,PPE and spread2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.pairplot(df.drop(['name'],axis=1), hue=\"status\", palette=\"husl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Considering all the fields values with status, we can notice two distinguished peaks but are close mostly signifying the mode values for status are close by \n",
    "- Majority of fields has significant overlap area visible for status 0 and 1 in the kde plots\n",
    "- We have clear indicators in many attributes that low and high values are belonging to a certain group rather then covered by both status 0 and 1. This indicates the outliers or high or low values usually belong to one group rather than both making it ambigous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Analyzing Frequencies\n",
    "- MDVP:Fo(Hz) - Average vocal fundamental frequency\n",
    "- MDVP:Fhi(Hz) - Maximum vocal fundamental frequency\n",
    "- MDVP:Flo(Hz) - Minimum vocal fundamental frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axes = plt.subplots(1, 3, figsize=(15,8))\n",
    "\n",
    "sns.boxplot(x=df['status'],y=df['MDVP:Fo(Hz)'],ax=axes[0])\n",
    "sns.boxplot(x=df['status'],y=df['MDVP:Flo(Hz)'],ax=axes[1])\n",
    "sns.boxplot(x=df['status'],y=df['MDVP:Fhi(Hz)'],ax=axes[2])\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Viewing on same Y axis\n",
    "f, axes = plt.subplots(1, 3, figsize=(15,8),sharey='row')\n",
    "\n",
    "sns.boxplot(x=df['status'],y=df['MDVP:Fo(Hz)'],ax=axes[0])\n",
    "sns.boxplot(x=df['status'],y=df['MDVP:Flo(Hz)'],ax=axes[1])\n",
    "sns.boxplot(x=df['status'],y=df['MDVP:Fhi(Hz)'],ax=axes[2])\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Considering both the boxplots\n",
    "- There is a significant variation in median for status 0 and 1 for  Averagea and Maximum vocal frequency.\n",
    "- Median for Average on staus 0 is close to 200 and for status 1 is around 150\n",
    "- Median for Maximum on staus 0 is close to 250 and for status 1 is around 150\n",
    "- Few outliers presence for Maximum vocal frequencies\n",
    "- For status 0 - box and whisker has much higher range compared to status 1 in all 3 vocal fundamental frequencies\n",
    "- There is big overlap in range of frequencies for status 0 and 1 but majorly the higher ranges are covered with status 0\n",
    "- For maximum vocal frequencies majority of outliers were belong to status 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Analyzing\n",
    "- MDVP:Jitter(%),MDVP:Jitter(Abs),MDVP:RAP,MDVP:PPQ,Jitter:DDP - Several measures of variation in fundamental frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axes = plt.subplots(2,3,figsize=(15,15)) \n",
    "sns.boxplot(x=df['status'],y=df['MDVP:Jitter(%)'],ax=axes[0,0])\n",
    "sns.boxplot(x=df['status'],y=df['MDVP:Jitter(Abs)'],ax=axes[0,1])\n",
    "sns.boxplot(x=df['status'],y=df['MDVP:RAP'],ax=axes[0,2])\n",
    "sns.boxplot(x=df['status'],y=df['MDVP:PPQ'],ax=axes[1,0])\n",
    "sns.boxplot(x=df['status'],y=df['Jitter:DDP'],ax=axes[1,1]) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- High presence of outliers in attributes realted to jitter\n",
    "- For status 1 - whiskers and box were having more range and majorly all outliers are belonging to status 1.\n",
    "- Majority of higher values and outliers are belonging to status 1\n",
    "- Suggests the higher presence jitter is a strong indicator of Parkinson's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Analyzing \n",
    "- MDVP:Shimmer,MDVP:Shimmer(dB),Shimmer:APQ3,Shimmer:APQ5,MDVP:APQ,Shimmer:DDA - Several measures of variation in amplitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axes = plt.subplots(2, 3, figsize=(15,15))\n",
    "\n",
    "sns.boxplot(x=df['status'],y=df['MDVP:Shimmer'],ax=axes[0,0] )\n",
    "sns.boxplot(x=df['status'],y=df['MDVP:Shimmer(dB)'],ax=axes[0,1] )\n",
    "sns.boxplot(x=df['status'],y=df['Shimmer:APQ3'],ax=axes[0,2])\n",
    "sns.boxplot(x=df['status'],y=df['Shimmer:APQ5'],ax=axes[1,0])\n",
    "sns.boxplot(x=df['status'],y=df['MDVP:APQ'],ax=axes[1,1]) \n",
    "sns.boxplot(x=df['status'],y=df['Shimmer:DDA'],ax=axes[1,2])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Noticing similar behaviour like JItter\n",
    "- whiskers and boxes are having higher ranges for status 1 compared to 0\n",
    "- Majority of higher values and outliers are belonging to status 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Analyzing NHR & HNR - Noises\n",
    "- NHR,HNR - Two measures of ratio of noise to tonal components in the voice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axes = plt.subplots(1, 2, figsize=(15,8))\n",
    "\n",
    "sns.boxplot(x=df['status'],y=df['NHR'],ax=axes[0])\n",
    "sns.boxplot(x=df['status'],y=df['HNR'],ax=axes[1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- status 1 has higher range of whisker and box comapred to status 0 for both NHR and HNR\n",
    "- for NHR, majority of higher values or outliers are for status 1, beyond 0.15 all are for status 1\n",
    "- for HNR as well majority of outliers towards low range values are also for status 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Analyzing RPDE,D2 \n",
    "- Two nonlinear dynamical complexity measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axes = plt.subplots(1, 2, figsize=(15,8))\n",
    "\n",
    "sns.boxplot(x=df['status'],y=df['RPDE'],ax=axes[0])\n",
    "sns.boxplot(x=df['status'],y=df['D2'],ax=axes[1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- For RPDE,  whisker and boxes are of similar range.\n",
    "- For D2, majority fo outliers wre belonging to status 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Analyzing DFA - Signal fractal scaling exponent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x=df['status'],y=df['DFA'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- whisker is much bigger for status 1 compared to 0.\n",
    "- values above .8 and below 0.6 belongs to status 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Analyzing spread1,spread2,PPE \n",
    "- Three nonlinear measures of fundamental frequency variation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axes = plt.subplots(1, 3, figsize=(15,8))\n",
    "\n",
    "sns.boxplot(x=df['status'],y=df['spread1'],ax=axes[0])\n",
    "sns.boxplot(x=df['status'],y=df['spread2'],ax=axes[1])\n",
    "sns.boxplot(x=df['status'],y=df['PPE'],ax=axes[2])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- High range values for spread1, spread2 and PPE are covered under status 1, and low range values for status 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Null Values and Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- No Null/nan values found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.drop(\"name\",axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler=MinMaxScaler((-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=scaler.fit_transform( df.loc[:,df.columns != 'status'].values[:,1:])\n",
    "y=df.loc[:,'status'].values\n",
    "X[:,0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X = df.drop(\"status\",axis=1)\n",
    "#Y = df[\"status\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the dataset into training and test set in the ratio of 70:30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train,  y_test = train_test_split(X, y,train_size=0.7, random_state=10)\n",
    "print(len(X_train)),print(len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Data is scalled as we have lot of attributes having very diff range of values\n",
    "- Data set is distributed into training and test set\n",
    "- We have very less volume of data to train and even lesser volume to test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "def draw_cm( actual, predicted ):\n",
    "    cm = metrics.confusion_matrix( actual, predicted, [0,1] )\n",
    "    sns.heatmap(cm, annot=True,  fmt='.0f', xticklabels = [\"Status 0\", \"Status 1\"] , yticklabels = [\"Status 0\", \"Status 1\"] )\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelComp=pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and test Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logRegModel=LogisticRegression()\n",
    "logRegModel.fit(X_train,y_train)\n",
    "y_predict=logRegModel.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix,recall_score,f1_score,precision_score,roc_curve,log_loss,auc\n",
    "print('Accuracy score:',accuracy_score(y_test,y_predict))\n",
    "print('confuion matrix:\\n',confusion_matrix(y_test,y_predict))\n",
    "print('Recall Score: ',recall_score(y_test, y_predict))\n",
    "print('Precission Score: ',precision_score(y_test, y_predict))\n",
    "print('F1 Score: ',f1_score(y_test, y_predict))\n",
    "draw_cm(y_test, y_predict)\n",
    "modelComp=pd.DataFrame({'Model':['Logistic Regression - 0.5'],'Accuracy':[accuracy_score(y_test,y_predict)*100],'Precission':[precision_score(y_test, y_predict)*100],'Recall':[recall_score(y_test, y_predict)*100]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import binarize\n",
    "#changing the threshold to 0.4\n",
    "y_pred_class = binarize([logRegModel.predict_proba(X_test)[:, 1]], 0.4)[0]\n",
    "\n",
    "print('Accuracy score:',accuracy_score(y_test,y_pred_class))\n",
    "print('confuion matrix:\\n',confusion_matrix(y_test,y_pred_class))\n",
    "print('Recall Score: ',recall_score(y_test, y_pred_class))\n",
    "print('Precission Score: ',precision_score(y_test, y_pred_class))\n",
    "print('F1 Score: ',f1_score(y_test, y_pred_class))\n",
    "draw_cm(y_test, y_pred_class)\n",
    "modelComp=modelComp.append(pd.DataFrame({'Model':['Logistic Regression - 0.4'],'Accuracy':[accuracy_score(y_test,y_pred_class)*100],'Precission':[precision_score(y_test, y_pred_class)*100],'Recall':[recall_score(y_test, y_pred_class)*100]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "KnnModel = KNeighborsClassifier(n_neighbors=3)\n",
    "KnnModel.fit(X_train,y_train)\n",
    "y_predict=KnnModel.predict(X_test)\n",
    "\n",
    "print('Accuracy score:',accuracy_score(y_test,y_predict))\n",
    "print('confuion matrix:\\n',confusion_matrix(y_test,y_predict))\n",
    "print('Recall Score: ',recall_score(y_test, y_predict))\n",
    "print('Precission Score: ',precision_score(y_test, y_predict))\n",
    "print('F1 Score: ',f1_score(y_test, y_predict))\n",
    "\n",
    "draw_cm(y_test, y_predict)\n",
    "modelComp=modelComp.append(pd.DataFrame({'Model':['KNN - 3 Neigbours'],'Accuracy':[accuracy_score(y_test,y_predict)*100],'Precission':[precision_score(y_test, y_predict)*100],'Recall':[recall_score(y_test, y_predict)*100]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NaiveBayes Gaussian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB,BernoulliNB\n",
    "NBGauModel = GaussianNB()\n",
    "\n",
    "NBGauModel.fit(X_train,y_train)\n",
    "y_predict=NBGauModel.predict(X_test)\n",
    "\n",
    "print('Accuracy score:',accuracy_score(y_test,y_predict))\n",
    "print('confuion matrix:\\n',confusion_matrix(y_test,y_predict))\n",
    "print('Recall Score: ',recall_score(y_test, y_predict))\n",
    "print('Precission Score: ',precision_score(y_test, y_predict))\n",
    "print('F1 Score: ',f1_score(y_test, y_predict))\n",
    "draw_cm(y_test, y_predict)\n",
    "modelComp=modelComp.append(pd.DataFrame({'Model':['Naive Bayes - Gaussian'],'Accuracy':[accuracy_score(y_test,y_predict)*100],'Precission':[precision_score(y_test, y_predict)*100],'Recall':[recall_score(y_test, y_predict)*100]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "clf = SVC(kernel='linear')\n",
    "\n",
    "clf.fit(X_train,y_train)\n",
    "y_predict=clf.predict(X_test)\n",
    "\n",
    "print('Accuracy score:',accuracy_score(y_test,y_predict))\n",
    "print('confuion matrix:\\n',confusion_matrix(y_test,y_predict))\n",
    "print('Recall Score: ',recall_score(y_test, y_predict))\n",
    "print('Precission Score: ',precision_score(y_test, y_predict))\n",
    "print('F1 Score: ',f1_score(y_test, y_predict))\n",
    "draw_cm(y_test, y_predict)\n",
    "modelComp=modelComp.append(pd.DataFrame({'Model':['SVC'],'Accuracy':[accuracy_score(y_test,y_predict)*100],'Precission':[precision_score(y_test, y_predict)*100],'Recall':[recall_score(y_test, y_predict)*100]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Comapring Accuracy precission and Recall \n",
    "modelComp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Considering the standard classification algorithm, SVM and Logistic Regression provided us with best Accuracy Precission and Recall values\n",
    "- Updating the threshold to 0.4 for logistic is providing us with best recall values but its taking a hit on Precissiona dn overall accuracy as well.\n",
    "- Considering that SVM has a better Overall values with Recall\n",
    "- A 100% Recall score is good but we have a very small sample size and while using it on real world data might give us a unexpected or biased results. We should be looking at a model with best on all qalities and not a 100%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#META classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "#Base Learners\n",
    "#knn_clf = KNeighborsClassifier(n_neighbors=3)\n",
    "#svc_clf = SVC(kernel='linear')\n",
    "#lr_clf = LogisticRegression(max_iter=10000)\n",
    "#nb_Gau_clf=GaussianNB()\n",
    "estimators = [('knn_clf',KNeighborsClassifier(n_neighbors=3)),\n",
    "              ('nb_clf',GaussianNB()),\n",
    "             ('lr_clf',LogisticRegression()),\n",
    "             ('svc_clf',SVC(kernel='linear'))]\n",
    "lr = LogisticRegression(max_iter=10000) # meta classifier\n",
    "sclf = StackingClassifier(estimators=estimators, final_estimator=lr)\n",
    "\n",
    "sclf.fit(X_train,y_train)\n",
    "y_predict=sclf.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "print('Accuracy score:',accuracy_score(y_test,y_predict))\n",
    "print('confuion matrix:\\n',confusion_matrix(y_test,y_predict))\n",
    "print('Recall Score: ',recall_score(y_test, y_predict))\n",
    "print('Precission Score: ',precision_score(y_test, y_predict))\n",
    "print('F1 Score: ',f1_score(y_test, y_predict))\n",
    "draw_cm(y_test, y_predict)\n",
    "modelComp=modelComp.append(pd.DataFrame({'Model':['Stacking Classifier(KNN,NB,LR,SVC)LR'],'Accuracy':[accuracy_score(y_test,y_predict)*100],'Precission':[precision_score(y_test, y_predict)*100],'Recall':[recall_score(y_test, y_predict)*100]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_proba = sclf.predict_proba(X_test)[:, 1]\n",
    "[fpr, tpr, thr] = roc_curve(y_test, y_pred_proba)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='coral', label='ROC curve Stacking - LogReg(area = %0.3f)' % auc(fpr, tpr))\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate (1 - specificity)', fontsize=14)\n",
    "plt.ylabel('True Positive Rate (recall)', fontsize=14)\n",
    "plt.title('Receiver operating characteristic (ROC) curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelComp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- With Stacking Classifier\n",
    "- We can notice the stacking classifer has provided the best accuracy while trying to keep better Recall and preceission values\n",
    "- SVC has 100% Recall and NB has 100% Precission but overall accuracy was slight low\n",
    "- With stacking classifer we can observe it attained the highest Accuracy with next to best Precission and Recall. Only 1 value is missclassified from Status 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Changing the final estimator to SVC in stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = [('knn_clf',KNeighborsClassifier(n_neighbors=3)),\n",
    "              ('nb_clf',GaussianNB()),\n",
    "             ('lr_clf',LogisticRegression()),\n",
    "             ('svc_clf',SVC(kernel='linear'))]\n",
    "lr = LogisticRegression() # meta classifier\n",
    "sclf = StackingClassifier(estimators=estimators, final_estimator=SVC(kernel='linear'))\n",
    "\n",
    "sclf.fit(X_train,y_train)\n",
    "y_predict=sclf.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "print('Accuracy score:',accuracy_score(y_test,y_predict))\n",
    "print('confuion matrix:\\n',confusion_matrix(y_test,y_predict))\n",
    "print('Recall Score: ',recall_score(y_test, y_predict))\n",
    "print('Precission Score: ',precision_score(y_test, y_predict))\n",
    "print('F1 Score: ',f1_score(y_test, y_predict))\n",
    "draw_cm(y_test, y_predict)\n",
    "modelComp=modelComp.append(pd.DataFrame({'Model':['Stacking Classifier(KNN,NB,LR,SVC)SVC'],'Accuracy':[accuracy_score(y_test,y_predict)*100],'Precission':[precision_score(y_test, y_predict)*100],'Recall':[recall_score(y_test, y_predict)*100]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelComp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Changing the final estimator to GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = [('knn_clf',KNeighborsClassifier(n_neighbors=3)),\n",
    "              ('nb_clf',GaussianNB()),\n",
    "             ('lr_clf',LogisticRegression()),\n",
    "             ('svc_clf',SVC(kernel='linear'))]\n",
    "lr = LogisticRegression() # meta classifier\n",
    "sclf = StackingClassifier(estimators=estimators, final_estimator=GaussianNB())\n",
    "\n",
    "sclf.fit(X_train,y_train)\n",
    "y_predict=sclf.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "print('Accuracy score:',accuracy_score(y_test,y_predict))\n",
    "print('confuion matrix:\\n',confusion_matrix(y_test,y_predict))\n",
    "print('Recall Score: ',recall_score(y_test, y_predict))\n",
    "print('Precission Score: ',precision_score(y_test, y_predict))\n",
    "print('F1 Score: ',f1_score(y_test, y_predict))\n",
    "draw_cm(y_test, y_predict)\n",
    "modelComp=modelComp.append(pd.DataFrame({'Model':['Stacking Classifier(KNN,NB,LR,SVC)NB'],'Accuracy':[accuracy_score(y_test,y_predict)*100],'Precission':[precision_score(y_test, y_predict)*100],'Recall':[recall_score(y_test, y_predict)*100]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelComp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- On stacking classifiers, with different Final estimator we can observe the algorithm is trying its best to provide a best result.\n",
    "- Stacking Classifier with Logistic is by far providing us with best results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Decission Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dt_model = DecisionTreeClassifier(criterion='entropy',max_depth=5,random_state=10,min_samples_leaf=5)\n",
    "dt_model.fit(X_train, y_train)\n",
    "y_predict=dt_model.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "print('Accuracy score:',accuracy_score(y_test,y_predict))\n",
    "print('confuion matrix:\\n',confusion_matrix(y_test,y_predict))\n",
    "print('Recall Score: ',recall_score(y_test, y_predict))\n",
    "print('Precission Score: ',precision_score(y_test, y_predict))\n",
    "print('F1 Score: ',f1_score(y_test, y_predict))\n",
    "draw_cm(y_test, y_predict)\n",
    "modelComp=modelComp.append(pd.DataFrame({'Model':['Decision Tree'],'Accuracy':[accuracy_score(y_test,y_predict)*100],'Precission':[precision_score(y_test, y_predict)*100],'Recall':[recall_score(y_test, y_predict)*100]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_proba = dt_model.predict_proba(X_test)[:, 1]\n",
    "[fpr0, tpr0, thr0] = roc_curve(y_test, y_pred_proba)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label='ROC curve Stacking - LogReg(area = %0.3f)' % auc(fpr, tpr))\n",
    "plt.plot(fpr0, tpr0, label='ROC curve DecissionTree(area = %0.3f)' % auc(fpr0, tpr0))\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate (1 - specificity)', fontsize=14)\n",
    "plt.ylabel('True Positive Rate (recall)', fontsize=14)\n",
    "plt.title('Receiver operating characteristic (ROC) curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelComp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Decission Tree with very minimal changes itself is able to provide us with a very better solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bagging Classifer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "bgclf = BaggingClassifier(base_estimator=dt_model, n_estimators=50, max_samples=.7)\n",
    "bgclf = bgclf.fit(X_train, y_train)\n",
    "\n",
    "y_predict=bgclf.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "print('Accuracy score:',accuracy_score(y_test,y_predict))\n",
    "print('confuion matrix:\\n',confusion_matrix(y_test,y_predict))\n",
    "print('Recall Score: ',recall_score(y_test, y_predict))\n",
    "print('Precission Score: ',precision_score(y_test, y_predict))\n",
    "print('F1 Score: ',f1_score(y_test, y_predict))\n",
    "draw_cm(y_test, y_predict)\n",
    "modelComp=modelComp.append(pd.DataFrame({'Model':['BaggingClassifier'],'Accuracy':[accuracy_score(y_test,y_predict)*100],'Precission':[precision_score(y_test, y_predict)*100],'Recall':[recall_score(y_test, y_predict)*100]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_proba = bgclf.predict_proba(X_test)[:, 1]\n",
    "[fpr1, tpr1, thr1] = roc_curve(y_test, y_pred_proba)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label='ROC curve Stacking - LogReg(area = %0.3f)' % auc(fpr, tpr))\n",
    "plt.plot(fpr0, tpr0, label='ROC curve DecissionTree(area = %0.3f)' % auc(fpr0, tpr0))\n",
    "plt.plot(fpr1, tpr1, label='ROC curve Bagging - DT(area = %0.3f)' % auc(fpr1, tpr1))\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate (1 - specificity)', fontsize=14)\n",
    "plt.ylabel('True Positive Rate (recall)', fontsize=14)\n",
    "plt.title('Receiver operating characteristic (ROC) curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelComp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- With Bagging Classifer we can observe it is able to provide us best Accuracy, without hampering too much on Precission and Recall rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Applying Ensemble Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfclf = RandomForestClassifier(n_estimators = 50)\n",
    "rfclf.fit(X_train, y_train)\n",
    "\n",
    "y_predict=rfclf.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "print('Accuracy score:',accuracy_score(y_test,y_predict))\n",
    "print('confuion matrix:\\n',confusion_matrix(y_test,y_predict))\n",
    "print('Recall Score: ',recall_score(y_test, y_predict))\n",
    "print('Precission Score: ',precision_score(y_test, y_predict))\n",
    "print('F1 Score: ',f1_score(y_test, y_predict))\n",
    "draw_cm(y_test, y_predict)\n",
    "modelComp=modelComp.append(pd.DataFrame({'Model':['Random Forest'],'Accuracy':[accuracy_score(y_test,y_predict)*100],'Precission':[precision_score(y_test, y_predict)*100],'Recall':[recall_score(y_test, y_predict)*100]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_proba = rfclf.predict_proba(X_test)[:, 1]\n",
    "[fpr2, tpr2, thr2] = roc_curve(y_test, y_pred_proba)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label='ROC curve Stacking - LogReg(area = %0.3f)' % auc(fpr, tpr))\n",
    "plt.plot(fpr0, tpr0, label='ROC curve DecissionTree(area = %0.3f)' % auc(fpr0, tpr0))\n",
    "plt.plot(fpr1, tpr1, label='ROC curve Bagging - DT(area = %0.3f)' % auc(fpr1, tpr1))\n",
    "plt.plot(fpr2, tpr2, label='ROC curve RandomForest(area = %0.3f)' % auc(fpr2, tpr2))\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate (1 - specificity)', fontsize=14)\n",
    "plt.ylabel('True Positive Rate (recall)', fontsize=14)\n",
    "plt.title('Receiver operating characteristic (ROC) curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelComp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Random Forest & Bagging Classifier is able to provide us with best solution so far with 93.2% accuracy, 93% precission and 97.67% Recall.\n",
    "- Total 4 values are missclassifed but only 1 missclassification for status 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADABOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "abcl = AdaBoostClassifier( n_estimators= 20) \n",
    "abcl.fit(X_train, y_train)\n",
    "y_predict=abcl.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "print('Accuracy score:',accuracy_score(y_test,y_predict))\n",
    "print('confuion matrix:\\n',confusion_matrix(y_test,y_predict))\n",
    "print('Recall Score: ',recall_score(y_test, y_predict))\n",
    "print('Precission Score: ',precision_score(y_test, y_predict))\n",
    "print('F1 Score: ',f1_score(y_test, y_predict))\n",
    "draw_cm(y_test, y_predict)\n",
    "modelComp=modelComp.append(pd.DataFrame({'Model':['Ada Boost'],'Accuracy':[accuracy_score(y_test,y_predict)*100],'Precission':[precision_score(y_test, y_predict)*100],'Recall':[recall_score(y_test, y_predict)*100]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_proba = abcl.predict_proba(X_test)[:, 1]\n",
    "[fpr3_0, tpr3_0, thr3_0] = roc_curve(y_test, y_pred_proba)\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.plot(fpr, tpr, label='ROC curve Stacking - LogReg(area = %0.3f)' % auc(fpr, tpr))\n",
    "plt.plot(fpr0, tpr0, label='ROC curve DecissionTree(area = %0.3f)' % auc(fpr0, tpr0))\n",
    "plt.plot(fpr1, tpr1, label='ROC curve Bagging - DT(area = %0.3f)' % auc(fpr1, tpr1))\n",
    "plt.plot(fpr2, tpr2, label='ROC curve RandomForest(area = %0.3f)' % auc(fpr2, tpr2))\n",
    "plt.plot(fpr3_0, tpr3_0, label='ROC curve AdaBost(area = %0.3f)' % auc(fpr3_0, tpr3_0))\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate (1 - specificity)', fontsize=14)\n",
    "plt.ylabel('True Positive Rate (recall)', fontsize=14)\n",
    "plt.title('Receiver operating characteristic (ROC) curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelComp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gradient Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "gbcl = GradientBoostingClassifier(n_estimators = 1000, learning_rate = 0.001)\n",
    "gbcl = gbcl.fit(X_train, y_train)\n",
    "y_predict=gbcl.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "print('Accuracy score:',accuracy_score(y_test,y_predict))\n",
    "print('confuion matrix:\\n',confusion_matrix(y_test,y_predict))\n",
    "print('Recall Score: ',recall_score(y_test, y_predict))\n",
    "print('Precission Score: ',precision_score(y_test, y_predict))\n",
    "print('F1 Score: ',f1_score(y_test, y_predict))\n",
    "draw_cm(y_test, y_predict)\n",
    "modelComp=modelComp.append(pd.DataFrame({'Model':['GradientBoostingClassifier'],'Accuracy':[accuracy_score(y_test,y_predict)*100],'Precission':[precision_score(y_test, y_predict)*100],'Recall':[recall_score(y_test, y_predict)*100]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_proba = gbcl.predict_proba(X_test)[:, 1]\n",
    "[fpr3, tpr3, thr3] = roc_curve(y_test, y_pred_proba)\n",
    "\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.plot(fpr, tpr, label='ROC curve Stacking - LogReg(area = %0.3f)' % auc(fpr, tpr))\n",
    "plt.plot(fpr0, tpr0, label='ROC curve DecissionTree(area = %0.3f)' % auc(fpr0, tpr0))\n",
    "plt.plot(fpr1, tpr1, label='ROC curve Bagging - DT(area = %0.3f)' % auc(fpr1, tpr1))\n",
    "plt.plot(fpr2, tpr2, label='ROC curve RandomForest(area = %0.3f)' % auc(fpr2, tpr2))\n",
    "plt.plot(fpr3_0, tpr3_0, label='ROC curve AdaBost(area = %0.3f)' % auc(fpr3_0, tpr3_0))\n",
    "plt.plot(fpr3, tpr3, label='ROC curve GradientBoost(area = %0.3f)' % auc(fpr3, tpr3))\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate (1 - specificity)', fontsize=14)\n",
    "plt.ylabel('True Positive Rate (recall)', fontsize=14)\n",
    "plt.title('Receiver operating characteristic (ROC) curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelComp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Cosiderin all the Model's we can clearly notice the Ensemble models are providing better overall results\n",
    "- Among the Classifers, Random Forest, AdaBoost, Bagging classifiers has provided us with best Accuracy, precission and recall in a single package. Mostly are based on decission trees.\n",
    "- ROC curve for AdaBoost, Random Forest and Stacking - with final estimator as logistic regression has best AUC. If we observe the shape of the ROC for these graphs we can notice a slight different patttern for those. Classifiers that give curves closer to the top-left corner indicate a better performance.\n",
    "- ROC curve for Decission tree is a lot diffeent then other models, the reason why it occurs in a decision tree is that you often do binary splits; this is efficient computationally, but only gives 2^n groupings. Unless your n number of splits are very large, you'll only have 16/32/64/128 groups, whereas if you used an algorithm such as logistic regression and used continous variables, your prediction would fall in the continous range between 0 and 1. As our model can only provide discrete predictions, rather than a continous score. This can often be remedied by adding more samples to your dataset, having more continous features in the model, more features in general or using a model specification that provides a continous prediction output.\n",
    "- Considering few of the top models with best accuracy and recall, the ROC curve (area), we can can notice AdaBoost, Random Forest and Stacking - LogReg have close values, but Random Forest has much better overall accuracy along with AUC and hence we are considering it as our best model for the Task."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
